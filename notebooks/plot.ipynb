{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/ryanpilgrim/projects/ip-is-all-you-need/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "c = pl.col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"./results/results.parquet\").drop(\"output_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trial(experiment_number, algorithm, metric, trial):\n",
    "    df_filtered = df.filter(\n",
    "        (c(\"experiment_number\") == experiment_number)\n",
    "        & (c(\"algorithm\") == algorithm)\n",
    "        & (c(\"trial\") == trial)\n",
    "    ).sort(\"iter\")\n",
    "    if metric.startswith(\"mse\"):\n",
    "        metric_values = 10 * df_filtered[metric].log10()\n",
    "    else:\n",
    "        metric_values = df_filtered[metric]\n",
    "    plt.plot(df_filtered[\"iter\"], metric_values)\n",
    "    plt.vlines([df_filtered[\"nnz\"][0] - 1], metric_values.min(), metric_values.max(), linestyles=[\"--\"])\n",
    "\n",
    "\n",
    "plot_trial(0, \"ip\", \"mse_x\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set num_buckets per experiment setting\n",
    "num_buckets = 20\n",
    "\n",
    "# \"time series\" data: average over trials\n",
    "df_ts = (\n",
    "    df.with_columns(\n",
    "        ((c(\"iter\") + 1) / c(\"nnz\")).alias(\"rel_iter\"),\n",
    "    ).with_columns(\n",
    "        (c(\"rel_iter\") * num_buckets).floor().cast(pl.UInt32).alias(\"rel_iter_bucket\"),\n",
    "    )\n",
    "    .filter(c(\"rel_iter\") <= 1.0)\n",
    "    .groupby([\"experiment_number\", \"rel_iter_bucket\", \"algorithm\"])\n",
    "    .agg(\n",
    "        c(\"m\").first(),\n",
    "        c(\"n\").first(),\n",
    "        c(\"measurement_rate\").first(),\n",
    "        c(\"mean_sparsity\").first(),\n",
    "        c(\"noise_std\").first(),\n",
    "        c(\"nnz\").first(),\n",
    "        c(\"rel_iter\").mean(),\n",
    "        c(\"coherence\").mean(),\n",
    "        # mean\n",
    "        c(\"mse_x\").mean().alias(\"mse_x_mean\"),\n",
    "        c(\"mse_y\").mean().alias(\"mse_y_mean\"),\n",
    "        (c(\"mse_x\") / c(\"norm_x\")).mean().alias(\"rel_mse_x_mean\"),\n",
    "        (c(\"mse_y\") / c(\"norm_y\")).mean().alias(\"rel_mse_y_mean\"),\n",
    "        c(\"precision\").mean().alias(\"precision_mean\"),\n",
    "        c(\"recall\").mean().alias(\"recall_mean\"),\n",
    "        c(\"iou\").mean().alias(\"iou_mean\"),\n",
    "        # median\n",
    "        c(\"mse_x\").median().alias(\"mse_x_median\"),\n",
    "        c(\"mse_y\").median().alias(\"mse_y_median\"),\n",
    "        (c(\"mse_x\") / c(\"norm_x\")).median().alias(\"rel_mse_x_median\"),\n",
    "        (c(\"mse_y\") / c(\"norm_y\")).median().alias(\"rel_mse_y_median\"),\n",
    "        c(\"precision\").median().alias(\"precision_median\"),\n",
    "        c(\"recall\").median().alias(\"recall_median\"),\n",
    "        c(\"iou\").median().alias(\"iou_median\"),\n",
    "        # std\n",
    "        c(\"mse_x\").std().alias(\"mse_x_std\"),\n",
    "        c(\"mse_y\").std().alias(\"mse_y_std\"),\n",
    "        (c(\"mse_x\") / c(\"norm_x\")).std().alias(\"rel_mse_x_std\"),\n",
    "        (c(\"mse_y\") / c(\"norm_y\")).std().alias(\"rel_mse_y_std\"),\n",
    "        c(\"precision\").std().alias(\"precision_std\"),\n",
    "        c(\"recall\").std().alias(\"recall_std\"),\n",
    "        c(\"iou\").std().alias(\"iou_std\"),\n",
    "        # 1st quartile\n",
    "        c(\"mse_x\").quantile(0.25).alias(\"mse_x_lo\"),\n",
    "        c(\"mse_y\").quantile(0.25).alias(\"mse_y_lo\"),\n",
    "        (c(\"mse_x\") / c(\"norm_x\")).quantile(0.25).alias(\"rel_mse_x_lo\"),\n",
    "        (c(\"mse_y\") / c(\"norm_y\")).quantile(0.25).alias(\"rel_mse_y_lo\"),\n",
    "        c(\"precision\").quantile(0.25).alias(\"precision_lo\"),\n",
    "        c(\"recall\").quantile(0.25).alias(\"recall_lo\"),\n",
    "        c(\"iou\").quantile(0.25).alias(\"iou_lo\"),\n",
    "        # 3rd quartile\n",
    "        c(\"mse_x\").quantile(0.75).alias(\"mse_x_hi\"),\n",
    "        c(\"mse_y\").quantile(0.75).alias(\"mse_y_hi\"),\n",
    "        (c(\"mse_x\") / c(\"norm_x\")).quantile(0.75).alias(\"rel_mse_x_hi\"),\n",
    "        (c(\"mse_y\") / c(\"norm_y\")).quantile(0.75).alias(\"rel_mse_y_hi\"),\n",
    "        c(\"precision\").quantile(0.75).alias(\"precision_hi\"),\n",
    "        c(\"recall\").quantile(0.75).alias(\"recall_hi\"),\n",
    "        c(\"iou\").quantile(0.75).alias(\"iou_hi\"),\n",
    "        # min\n",
    "        c(\"iou\").min().alias(\"iou_min\"),\n",
    "        # max\n",
    "        c(\"iou\").max().alias(\"iou_max\"),\n",
    "    )\n",
    "    .sort([\"experiment_number\", \"algorithm\", \"rel_iter_bucket\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot(experiment_number: int, metric: str, central_tendency: str = \"mean\", error_bars: str = \"std\"):\n",
    "    xforms = defaultdict(lambda: identity)\n",
    "    xforms[\"rel_mse_x\"] = xforms[\"rel_mse_y\"] = lambda x: x.log10() * 10\n",
    "    xforms[\"mse_x\"] = xforms[\"mse_y\"] = lambda x: x.log10() * 10\n",
    "    xform = xforms[metric]\n",
    "    metric_to_ylabel = {\n",
    "        \"iou\": \"IOU\",\n",
    "        \"mse_x\": r\"$10 \\log_{10}(||x - \\widehat{x}||_2^2\\,/\\,||x||_2^2)$\",\n",
    "        \"mse_y\": r\"$10 \\log_{10}(||y - \\widehat{y}||_2^2\\,/\\,||y||_2^2)$\",\n",
    "        \"precision\": \"Precision\",\n",
    "        \"recall\": \"Recall\",\n",
    "    }\n",
    "    metric_to_title = {\n",
    "        \"iou\": \"IOU\",\n",
    "        \"mse_x\": r\"MSE($\\widehat{x}$) (dB)\",\n",
    "        \"mse_y\": r\"MSE($\\widehat{y}$) (dB)\",\n",
    "        \"precision\": \"Precision\",\n",
    "        \"recall\": \"Recall\",\n",
    "    }\n",
    "\n",
    "    df_ts_omp = df_ts.filter(\n",
    "        (c(\"algorithm\") == \"omp\") & (c(\"experiment_number\") == experiment_number)\n",
    "    )\n",
    "    df_ts_ip = df_ts.filter(\n",
    "        (c(\"algorithm\") == \"ip\") & (c(\"experiment_number\") == experiment_number)\n",
    "    )\n",
    "\n",
    "    m = df_ts_ip[\"m\"][0]\n",
    "    n = df_ts_ip[\"n\"][0]\n",
    "    s = df_ts_ip[\"mean_sparsity\"][0]\n",
    "    noise_std = df_ts_ip[\"noise_std\"][0]\n",
    "    coherence = df_ts_ip[\"coherence\"][0]\n",
    "\n",
    "    rel_iter_ip = df_ts_ip[\"rel_iter\"]\n",
    "    rel_iter_omp = df_ts_omp[\"rel_iter\"]\n",
    "    center_ip = df_ts_ip[f\"{metric}_{central_tendency}\"]\n",
    "    center_omp = df_ts_omp[f\"{metric}_{central_tendency}\"]\n",
    "    plt.plot(rel_iter_ip, xform(center_ip))\n",
    "\n",
    "    def plot_error_bars(rel_iter, center, df_ts):\n",
    "        if error_bars == \"iqr\":\n",
    "            plt.fill_between(\n",
    "                rel_iter,\n",
    "                xform(df_ts[f\"{metric}_lo\"]),\n",
    "                xform(df_ts[f\"{metric}_hi\"]),\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        elif error_bars == \"min_max\":\n",
    "            plt.fill_between(\n",
    "                rel_iter_ip,\n",
    "                xform(df_ts[f\"{metric}_min\"]),\n",
    "                xform(df_ts[f\"{metric}_max\"]),\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        elif error_bars == \"std\":\n",
    "            plt.fill_between(\n",
    "                rel_iter_ip,\n",
    "                xform(center - df_ts[f\"{metric}_std\"]),\n",
    "                xform(center + df_ts[f\"{metric}_std\"]),\n",
    "                alpha=0.3,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"error_bars value {error_bars} not understood.\")\n",
    "\n",
    "    plot_error_bars(rel_iter_ip, center_ip, df_ts_ip)\n",
    "\n",
    "    if metric != \"iou\":\n",
    "        plt.plot(\n",
    "            rel_iter_omp,\n",
    "            xform(center_omp),\n",
    "            \"--\",\n",
    "            marker=\"o\",\n",
    "            markerfacecolor=\"none\",\n",
    "        )\n",
    "        plot_error_bars(rel_iter_omp, center_omp, df_ts_omp)\n",
    "        plt.legend([\"IP Mean\", \"IP IQR\", \"OMP Mean\", \"OMP IQR\"])\n",
    "    else:\n",
    "        plt.legend([\"Mean\", \"Min/Max\"])\n",
    "    plt.xlabel(\"Iteration / # Iterations\")\n",
    "    plt.ylabel(f\"{metric_to_ylabel[metric]}\")\n",
    "    plt.title(f\"{metric_to_title[metric]}, m={m}, n={n}, s={s}, $\\\\sigma_n={noise_std}$, $\\\\mu={coherence:0.2f}$\")\n",
    "    plt.grid(\"on\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(0, \"mse_x\", error_bars=\"iqr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support recovery data (phase transition)\n",
    "df_pt = df.sort(\"iter\").groupby([\"experiment_number\", \"trial\"]).agg(\n",
    "    c(\"m\").first(),\n",
    "    c(\"n\").first(),\n",
    "    c(\"measurement_rate\").first(),\n",
    "    c(\"mean_sparsity\").first(),\n",
    "    c(\"noise_std\").first(),\n",
    "    c(\"precision\").last(),\n",
    "    c(\"recall\").last(),\n",
    "    c(\"iou\").last(),\n",
    "    (c(\"mse_x\") / c(\"norm_x\")).last().alias(\"rel_mse_x\"),\n",
    "    (c(\"mse_y\") / c(\"norm_y\")).last().alias(\"rel_mse_y\"),\n",
    ").groupby(\"experiment_number\").agg(\n",
    "    c(\"m\").first(),\n",
    "    c(\"n\").first(),\n",
    "    c(\"measurement_rate\").first(),\n",
    "    c(\"mean_sparsity\").first(),\n",
    "    c(\"noise_std\").first(),\n",
    "    # mean\n",
    "    c(\"precision\").mean(),\n",
    "    c(\"recall\").mean(),\n",
    "    c(\"iou\").mean(),\n",
    "    c(\"rel_mse_x\").mean(),\n",
    "    c(\"rel_mse_y\").mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pt.filter(c(\"noise_std\") == 0.0).select(\"rel_mse_x\", \"m\", \"n\", \"mean_sparsity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
